{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Download GR1 Arms Waist Dataset for Google Colab\n",
        "\n",
        "This notebook downloads specific tasks from the `nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim` dataset for the GR1 arms and waist embodiment. The downloaded data includes:\n",
        "\n",
        "- CanToDrawer\n",
        "- CupToDrawer \n",
        "- PlaceBottleToCabinet\n",
        "- PlacematToBowl\n",
        "- PotatoToMicrowave\n",
        "- TrayToPot\n",
        "\n",
        "Each task includes meta, data (chunk-000), and videos (chunk-000) folders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for Google Colab\n",
        "%pip install huggingface_hub\n",
        "%pip install --upgrade huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive for persistent storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to Hugging Face (optional - only needed if dataset requires authentication)\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Uncomment the line below if you need to authenticate\n",
        "# login()\n",
        "\n",
        "print(\"Google Drive mounted and Hugging Face setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Define the dataset repository\n",
        "REPO_ID = \"nvidia/PhysicalAI-Robotics-GR00T-X-Embodiment-Sim\"\n",
        "LOCAL_DIR = \"/content/drive/MyDrive/gr00t_dataset\"  # Persistent storage in Google Drive\n",
        "\n",
        "# Define the tasks and file patterns to download\n",
        "TASKS = [\n",
        "    \"gr1_arms_waist.CanToDrawer\",\n",
        "    \"gr1_arms_waist.CupToDrawer\", \n",
        "    \"gr1_arms_waist.CuttingBoardToBasket\",\n",
        "    \"gr1_arms_waist.CuttingBoardToCardboardBox\",\n",
        "    \"gr1_arms_waist.CuttingBoardToPan\",\n",
        "    \"gr1_arms_waist.CuttingBoardToPot\",\n",
        "    \"gr1_arms_waist.PlaceBottleToCabinet\",\n",
        "    \"gr1_arms_waist.PlaceMilkToMicrowave\",\n",
        "    \"gr1_arms_waist.PlacematToBowl\",\n",
        "    \"gr1_arms_waist.PotatoToMicrowave\",\n",
        "    \"gr1_arms_waist.TrayToPot\",\n",
        "    \"gr1_arms_waist.TrayToTieredShelf\",\n",
        "\n",
        "]\n",
        "\n",
        "# Create include patterns for all tasks\n",
        "include_patterns = []\n",
        "for task in TASKS:\n",
        "    include_patterns.extend([\n",
        "        f\"{task}/meta/**\",\n",
        "        f\"{task}/data/chunk-000/**\", \n",
        "        f\"{task}/videos/chunk-000/**\"\n",
        "    ])\n",
        "\n",
        "print(f\"Will download {len(TASKS)} tasks to: {LOCAL_DIR}\")\n",
        "print(f\"Tasks: {', '.join(TASKS)}\")\n",
        "print(f\"Total include patterns: {len(include_patterns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "print(\"Starting download...\")\n",
        "print(\"This may take several minutes depending on the dataset size and your connection speed.\")\n",
        "\n",
        "try:\n",
        "    snapshot_download(\n",
        "        repo_id=REPO_ID,\n",
        "        repo_type=\"dataset\",\n",
        "        local_dir=LOCAL_DIR,\n",
        "        allow_patterns=include_patterns,\n",
        "        resume_download=True  # Resume if interrupted\n",
        "    )\n",
        "    print(f\"\\n‚úÖ Download completed successfully!\")\n",
        "    print(f\"Dataset saved to: {LOCAL_DIR}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Download failed with error: {str(e)}\")\n",
        "    print(\"Please check your internet connection and try again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify the download by checking directory structure\n",
        "print(\"Verifying download...\")\n",
        "\n",
        "if os.path.exists(LOCAL_DIR):\n",
        "    print(f\"\\nüìÅ Contents of {LOCAL_DIR}:\")\n",
        "    \n",
        "    for task in TASKS:\n",
        "        task_path = os.path.join(LOCAL_DIR, task)\n",
        "        if os.path.exists(task_path):\n",
        "            print(f\"\\n‚úÖ {task}:\")\n",
        "            \n",
        "            # Check for meta, data, and videos directories\n",
        "            for subdir in [\"meta\", \"data/chunk-000\", \"videos/chunk-000\"]:\n",
        "                full_path = os.path.join(task_path, subdir)\n",
        "                if os.path.exists(full_path):\n",
        "                    file_count = len([f for f in os.listdir(full_path) if os.path.isfile(os.path.join(full_path, f))])\n",
        "                    print(f\"  üìÇ {subdir}: {file_count} files\")\n",
        "                else:\n",
        "                    print(f\"  ‚ùå {subdir}: Not found\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå {task}: Not found\")\n",
        "else:\n",
        "    print(f\"‚ùå Dataset directory not found: {LOCAL_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display dataset statistics\n",
        "print(\"Dataset Statistics:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "total_size = 0\n",
        "total_files = 0\n",
        "\n",
        "if os.path.exists(LOCAL_DIR):\n",
        "    for root, dirs, files in os.walk(LOCAL_DIR):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            total_size += file_size\n",
        "            total_files += 1\n",
        "    \n",
        "    # Convert bytes to human readable format\n",
        "    def human_readable_size(size_bytes):\n",
        "        for unit in ['B', 'KB', 'MB', 'GB']:\n",
        "            if size_bytes < 1024.0:\n",
        "                return f\"{size_bytes:.1f} {unit}\"\n",
        "            size_bytes /= 1024.0\n",
        "        return f\"{size_bytes:.1f} TB\"\n",
        "    \n",
        "    print(f\"Total files: {total_files}\")\n",
        "    print(f\"Total size: {human_readable_size(total_size)}\")\n",
        "    print(f\"Number of tasks: {len(TASKS)}\")\n",
        "    print(f\"Storage location: {LOCAL_DIR}\")\n",
        "else:\n",
        "    print(\"No dataset found to analyze.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Optional: Quick Data Exploration\n",
        "\n",
        "The cell below shows how to load and examine the downloaded data using GR00T's dataset loader. Uncomment and run if you want to explore the data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and run this cell if you want to explore the downloaded data structure\n",
        "\n",
        "\"\"\"\n",
        "# Example: Load and examine one task using GR00T's dataset loader\n",
        "# Note: You'll need to install the gr00t package first\n",
        "\n",
        "%pip install git+https://github.com/NVlabs/GR00T.git\n",
        "\n",
        "from gr00t.data.dataset import LeRobotSingleDataset\n",
        "from gr00t.data.dataset import ModalityConfig\n",
        "from gr00t.data.schema import EmbodimentTag\n",
        "\n",
        "# Example task to explore\n",
        "EXAMPLE_TASK = \"gr1_arms_waist.CanToDrawer\"\n",
        "TASK_PATH = os.path.join(LOCAL_DIR, EXAMPLE_TASK)\n",
        "\n",
        "if os.path.exists(TASK_PATH):\n",
        "    # Define modality configurations\n",
        "    modality_configs = {\n",
        "        \"video\": ModalityConfig(\n",
        "            delta_indices=[0],\n",
        "            modality_keys=[\"video.ego_view\"],\n",
        "        ),\n",
        "        \"state\": ModalityConfig(\n",
        "            delta_indices=[0],\n",
        "            modality_keys=[\n",
        "                \"state.left_arm\",\n",
        "                \"state.right_arm\", \n",
        "                \"state.left_hand\",\n",
        "                \"state.right_hand\",\n",
        "                \"state.waist\",\n",
        "            ],\n",
        "        ),\n",
        "        \"action\": ModalityConfig(\n",
        "            delta_indices=[0],\n",
        "            modality_keys=[\n",
        "                \"action.left_arm\",\n",
        "                \"action.right_arm\",\n",
        "                \"action.left_hand\", \n",
        "                \"action.right_hand\",\n",
        "                \"action.waist\",\n",
        "            ],\n",
        "        ),\n",
        "        \"language\": ModalityConfig(\n",
        "            delta_indices=[0],\n",
        "            modality_keys=[\"annotation.human.action.task_description\"],\n",
        "        ),\n",
        "    }\n",
        "    \n",
        "    # Load dataset\n",
        "    dataset = LeRobotSingleDataset(\n",
        "        TASK_PATH, \n",
        "        modality_configs, \n",
        "        embodiment_tag=EmbodimentTag.GR1_UNIFIED\n",
        "    )\n",
        "    \n",
        "    print(f\"Loaded dataset: {EXAMPLE_TASK}\")\n",
        "    print(f\"Dataset length: {len(dataset)}\")\n",
        "    \n",
        "    # Show first sample\n",
        "    sample = dataset[0]\n",
        "    print(f\"Sample keys: {list(sample.keys())}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"Task not found: {EXAMPLE_TASK}\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"Data exploration cell ready (uncomment to use)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Success message\n",
        "print(\"üéâ Dataset download complete!\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. The dataset is now available in:\", LOCAL_DIR)\n",
        "print(\"2. You can use this data with GR00T's data loaders\")\n",
        "print(\"3. Refer to other notebooks in this repository for training and inference examples\")\n",
        "print(\"4. The downloaded tasks are ready for fine-tuning or evaluation\")\n",
        "\n",
        "print(f\"\\nDownloaded tasks:\")\n",
        "for i, task in enumerate(TASKS, 1):\n",
        "    print(f\"{i}. {task}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
